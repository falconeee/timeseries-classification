{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc3274c",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, average_precision_score, accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import plotly.graph_objects as go\n",
    "from utils.futurai_ppd import drop_transitorio_desligado\n",
    "import matplotlib.pyplot as plt\n",
    "from sktime.datatypes._panel._convert import from_2d_array_to_nested\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea05d315",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d79ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = 'Depurador 762-28-006'\n",
    "timestamp = \"Timestamp\"\n",
    "\n",
    "df_dataset = pd.read_csv('data/' + base_name + '.csv', sep=\";\", decimal=\".\", encoding=\"utf-8-sig\")\n",
    "df_dataset[timestamp] = pd.to_datetime(df_dataset[timestamp], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "## Drop columns with NaN values, constant values or irrelevant to the analysis\n",
    "df_dataset.drop(columns=[\"762H0336.PV\", \"762H0342.PV\", \"762N0015.SP\", \"762P0013.SP\", \"762-34-073.CR\"], inplace=True, errors='ignore')\n",
    "## Drop rows with NaN values\n",
    "df_dataset.dropna(inplace=True)\n",
    "print(f\"Dataset shape: {df_dataset.shape}\")\n",
    "\n",
    "list_variables = df_dataset.columns.tolist()\n",
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb88f78a",
   "metadata": {},
   "source": [
    "## Remove periods Off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5447ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process = []\n",
    "pp_var_ref_desligado = \"762-28-006.CR\"\n",
    "pp_valor_ref_desligado = 5\n",
    "pp_tempo_ref_desligado = 0\n",
    "pp_pre_corte_transitorio = 0\n",
    "pp_pos_corte_transitorio = 0\n",
    "pre_process.append(  \n",
    "{\n",
    "   \"after_cut\": pp_pos_corte_transitorio,\n",
    "   \"interval_off\": pp_tempo_ref_desligado,\n",
    "   \"limit_off\": pp_valor_ref_desligado,\n",
    "   \"pre_cut\": pp_pre_corte_transitorio,\n",
    "   \"variable_off\": pp_var_ref_desligado\n",
    "  })\n",
    "\n",
    "for pro in pre_process:\n",
    "    df_dataset,_,_ = drop_transitorio_desligado(df_dataset,pro[\"variable_off\"],pro[\"limit_off\"],pro[\"interval_off\"],timestamp,pre_corte=pro[\"pre_cut\"],pos_corte=pro[\"after_cut\"])\n",
    "print(f\"Dataset shape: {df_dataset.shape}\")\n",
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570e0243",
   "metadata": {},
   "source": [
    "## Create label for anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c599f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodos_de_Falhas = [\n",
    "    (pd.Timestamp('2024-05-03 11:00:00'), pd.Timestamp('2024-05-03 11:35:00')),\n",
    "    (pd.Timestamp('2024-06-25 17:20:00'), pd.Timestamp('2024-08-02 14:00:00')),\n",
    "    (pd.Timestamp('2024-10-19 10:40:00'), pd.Timestamp('2024-10-19 10:50:00')),\n",
    "    (pd.Timestamp('2024-10-19 10:40:00'), pd.Timestamp('2024-10-19 10:50:00')),\n",
    "    (pd.Timestamp('2024-10-21 12:00:00'), pd.Timestamp('2024-10-22 00:35:00')),\n",
    "    (pd.Timestamp('2024-10-24 03:10:00'), pd.Timestamp('2024-10-27 00:00:00')),\n",
    "    (pd.Timestamp('2024-11-14 06:40:00'), pd.Timestamp('2024-11-14 19:45:00')),\n",
    "    (pd.Timestamp('2024-11-25 21:45:00'), pd.Timestamp('2024-11-25 22:03:00')),\n",
    "    (pd.Timestamp('2024-11-27 15:00:00'), pd.Timestamp('2024-11-27 15:07:00')),\n",
    "    (pd.Timestamp('2024-11-27 16:04:00'), pd.Timestamp('2024-11-26 16:11:00')),\n",
    "    (pd.Timestamp('2024-11-30 13:30:00'), pd.Timestamp('2024-11-30 15:52:00')),\n",
    "    (pd.Timestamp('2024-12-09 20:30:00'), pd.Timestamp('2024-12-11 07:00:00')),\n",
    "    (pd.Timestamp('2025-03-05 15:17:00'), pd.Timestamp('2025-03-05 15:24:00')),\n",
    "    (pd.Timestamp('2025-03-15 18:30:00'), pd.Timestamp('2025-03-15 19:15:00')),\n",
    "    (pd.Timestamp('2025-03-18 11:40:00'), pd.Timestamp('2025-03-18 20:00:00')),\n",
    "    (pd.Timestamp('2025-06-16 15:20:00'), pd.Timestamp('2025-06-17 07:38:00')),\n",
    "]\n",
    "\n",
    "df_dataset['Falhas'] = 0\n",
    "\n",
    "for inicio, fim in periodos_de_Falhas:\n",
    "    df_dataset.loc[(df_dataset[timestamp] >= inicio) & (df_dataset[timestamp] <= fim), 'Falhas'] = 1\n",
    "    \n",
    "df_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d334e30",
   "metadata": {},
   "source": [
    "## Import TAGs and descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e9acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subsistema = pd.read_csv('data/'+ base_name + '_subsistema.csv', sep=\";\", decimal=\".\", encoding=\"utf-8-sig\")\n",
    "df_subsistema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b24605",
   "metadata": {},
   "source": [
    "## Plot variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f46d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_dataset['Timestamp'],\n",
    "    y=df_dataset[\"762P0034.PV\"],\n",
    "    mode='lines',\n",
    "    name='762P0034.PV',\n",
    "    line=dict(color='black')\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_dataset['Timestamp'],\n",
    "    y=df_dataset[\"Falhas\"],\n",
    "    mode='lines',\n",
    "    name='Falhas',\n",
    "    line=dict(color='red')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_white',\n",
    "    hovermode='x unified'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690bf4fc",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a401316",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_dataset.set_index(timestamp)\n",
    "\n",
    "variables = df.drop(columns=[\"Falhas\"])\n",
    "labels = df[\"Falhas\"]\n",
    "\n",
    "window = \"60min\"\n",
    "\n",
    "agg_funcs = [\"mean\", \"std\", \"min\", \"max\", \"median\", \"skew\", \"var\", \"median\"]\n",
    "X_features = variables.resample(window).agg(agg_funcs)\n",
    "X_features.columns = ['_'.join(col).strip() for col in X_features.columns.values]\n",
    "\n",
    "## Most frequent label in the window, handling empty windows\n",
    "def most_frequent(x):\n",
    "    return x.mode().iloc[0] if not x.mode().empty else np.nan\n",
    "\n",
    "y_features = labels.resample(window).agg(most_frequent)\n",
    "\n",
    "## Remove windows with NaN in X or y\n",
    "X_features = X_features.dropna()\n",
    "y_features = y_features.loc[X_features.index].dropna()\n",
    "X_features = X_features.loc[y_features.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64524a3a",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755cc11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_train, X_features_test, y_features_train, y_features_test = train_test_split(X_features, y_features, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "## Scalling training set\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_features_train)\n",
    "X_features_train = pd.DataFrame(scaler.transform(X_features_train), columns=X_features_train.columns, index=X_features_train.index)\n",
    "X_features_test = pd.DataFrame(scaler.transform(X_features_test), columns=X_features_test.columns, index=X_features_test.index)\n",
    "\n",
    "\n",
    "## Verify class distribution in train and test sets\n",
    "print(\"Class distribution in training set (%):\")\n",
    "print(y_features_train.value_counts(normalize=True) * 100)\n",
    "print(\"\\nClass distribution in test set (%):\")\n",
    "print(y_features_test.value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e01cc46",
   "metadata": {},
   "source": [
    "### SMOTE training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac228a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_features_train_balanced, y_features_train_balanced = sm.fit_resample(X_features_train, y_features_train)\n",
    "\n",
    "## Verify class distribution in train and test sets\n",
    "print(\"Class distribution in training set (%):\")\n",
    "print(y_features_train_balanced.value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0293f3",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242eef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=400, \n",
    "    criterion='gini', \n",
    "    max_depth=None, \n",
    "    min_samples_split=2, \n",
    "    min_samples_leaf=1, \n",
    "    min_weight_fraction_leaf=0.0, \n",
    "    max_features='sqrt', \n",
    "    max_leaf_nodes=None, \n",
    "    min_impurity_decrease=0.0, \n",
    "    bootstrap=True, \n",
    "    oob_score=False, \n",
    "    n_jobs=None, \n",
    "    random_state=42, \n",
    "    verbose=0, \n",
    "    warm_start=False, \n",
    "    class_weight=None, \n",
    "    ccp_alpha=0.0, \n",
    "    max_samples=None, \n",
    "    monotonic_cst=None\n",
    ")\n",
    "\n",
    "## Cross validation\n",
    "k_folds = KFold(n_splits = 5)\n",
    "scores = cross_val_score(rf_clf, X_features_train_balanced, y_features_train_balanced, cv = k_folds)\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())\n",
    "print(\"Number of CV Scores used in Average: \", len(scores))\n",
    "\n",
    "## Fit model\n",
    "rf_clf.fit(X_features_train_balanced, y_features_train_balanced)\n",
    "\n",
    "## Predict and evaluate\n",
    "y_pred = rf_clf.predict(X_features_test)\n",
    "\n",
    "accuracy = accuracy_score(y_features_test, y_pred)\n",
    "f1 = f1_score(y_features_test, y_pred, average='binary')\n",
    "recall = recall_score(y_features_test, y_pred, average='binary')\n",
    "precision = precision_score(y_features_test, y_pred, average='binary')\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dcc8c5",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f5a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=400,      # número de árvores\n",
    "    learning_rate=0.1,     # taxa de aprendizado (quanto menor, mais estável, mas precisa mais árvores)\n",
    "    max_depth=6,           # profundidade máxima da árvore\n",
    "    subsample=0.8,         # fração de amostras usadas em cada árvore\n",
    "    colsample_bytree=0.8,  # fração de variáveis usadas em cada árvore\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\"  # ou \"mlogloss\" para multiclasse\n",
    ")\n",
    "\n",
    "## Cross validation\n",
    "k_folds = KFold(n_splits = 5)\n",
    "scores = cross_val_score(xgb_clf, X_features_train_balanced, y_features_train_balanced, cv = k_folds)\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())\n",
    "print(\"Number of CV Scores used in Average: \", len(scores))\n",
    "\n",
    "## Fit model\n",
    "xgb_clf.fit(X_features_train_balanced.to_numpy(), y_features_train_balanced.to_numpy())\n",
    "\n",
    "## Predict and evaluate\n",
    "y_pred = xgb_clf.predict(X_features_test.to_numpy())\n",
    "\n",
    "accuracy = accuracy_score(y_features_test, y_pred)\n",
    "f1 = f1_score(y_features_test, y_pred, average='binary')\n",
    "recall = recall_score(y_features_test, y_pred, average='binary')\n",
    "precision = precision_score(y_features_test, y_pred, average='binary')\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca542c3c",
   "metadata": {},
   "source": [
    "# New Data for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a495f7",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80984156",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = 'Depurador 762-28-006'\n",
    "timestamp = \"Timestamp\"\n",
    "\n",
    "df_dataset = pd.read_csv('data/' + base_name + '_teste.csv', sep=\";\", decimal=\".\", encoding=\"utf-8-sig\")\n",
    "df_dataset[timestamp] = pd.to_datetime(df_dataset[timestamp], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "df_dataset.drop_duplicates(subset=[timestamp], keep='first', inplace=True)\n",
    "df_dataset.sort_values(by=timestamp, inplace=True)\n",
    "## Drop columns with NaN values, constant values or irrelevant to the analysis\n",
    "df_dataset.drop(columns=[\"762H0336.PV\", \"762H0342.PV\", \"762N0015.SP\", \"762P0013.SP\", \"762-34-073.CR\"], inplace=True, errors='ignore')\n",
    "## Drop rows with NaN values\n",
    "df_dataset.dropna(inplace=True)\n",
    "print(f\"Dataset shape: {df_dataset.shape}\")\n",
    "df_dataset = df_dataset[list_variables]\n",
    "\n",
    "pre_process = []\n",
    "pp_var_ref_desligado = \"762-28-006.CR\"\n",
    "pp_valor_ref_desligado = 5\n",
    "pp_tempo_ref_desligado = 0\n",
    "pp_pre_corte_transitorio = 0\n",
    "pp_pos_corte_transitorio = 0\n",
    "pre_process.append(  \n",
    "{\n",
    "   \"after_cut\": pp_pos_corte_transitorio,\n",
    "   \"interval_off\": pp_tempo_ref_desligado,\n",
    "   \"limit_off\": pp_valor_ref_desligado,\n",
    "   \"pre_cut\": pp_pre_corte_transitorio,\n",
    "   \"variable_off\": pp_var_ref_desligado\n",
    "  })\n",
    "\n",
    "for pro in pre_process:\n",
    "    df_dataset,_,_ = drop_transitorio_desligado(df_dataset,pro[\"variable_off\"],pro[\"limit_off\"],pro[\"interval_off\"],timestamp,pre_corte=pro[\"pre_cut\"],pos_corte=pro[\"after_cut\"])\n",
    "print(f\"Dataset shape after remove offs: {df_dataset.shape}\")\n",
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eb352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_dataset['Timestamp'],\n",
    "    y=df_dataset[\"762P0034.PV\"],\n",
    "    mode='lines',\n",
    "    name='762P0034.PV',\n",
    "    line=dict(color='black')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_white',\n",
    "    hovermode='x unified'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f560be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = df_dataset.set_index(timestamp)\n",
    "\n",
    "variables = df_predict.drop(columns=[\"Falhas\"])\n",
    "labels = df_predict[\"Falhas\"]\n",
    "\n",
    "window = \"60min\"\n",
    "\n",
    "agg_funcs = [\"mean\", \"std\", \"min\", \"max\", \"median\", \"skew\", \"var\", \"median\"]\n",
    "X_features = variables.resample(window).agg(agg_funcs)\n",
    "X_features.columns = ['_'.join(col).strip() for col in X_features.columns.values]\n",
    "\n",
    "## Most frequent label in the window, handling empty windows\n",
    "def most_frequent(x):\n",
    "    return x.mode().iloc[0] if not x.mode().empty else np.nan\n",
    "\n",
    "y_features = labels.resample(window).agg(most_frequent)\n",
    "\n",
    "## Remove windows with NaN in X or y\n",
    "X_features = X_features.dropna()\n",
    "y_features = y_features.loc[X_features.index].dropna()\n",
    "X_features = X_features.loc[y_features.index]\n",
    "\n",
    "X_features = pd.DataFrame(scaler.transform(X_features), columns=X_features.columns, index=X_features.index)\n",
    "X_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b7a2af",
   "metadata": {},
   "source": [
    "# sktime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85e6591",
   "metadata": {},
   "source": [
    "## Train test split timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc38d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dataset.drop(columns=[\"Falhas\", timestamp])\n",
    "y = df_dataset[\"Falhas\"]\n",
    "\n",
    "X_raw_train, X_raw_test, y_raw_train, y_raw_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "## Verify class distribution in train and test sets\n",
    "print(\"Class distribution in training set (%):\")\n",
    "print(y_raw_train.value_counts(normalize=True) * 100)\n",
    "print(\"\\nClass distribution in test set (%):\")\n",
    "print(y_raw_test.value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a238c373",
   "metadata": {},
   "source": [
    "## Convert to sktime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19d2695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train and X_test conversion to sktime format\n",
    "X_train_sktime = from_2d_array_to_nested(X_raw_train.values)\n",
    "X_test_sktime = from_2d_array_to_nested(X_raw_test.values)\n",
    "\n",
    "# Keep labels the same for sktime\n",
    "y_train_sktime = y_raw_train\n",
    "y_test_sktime = y_raw_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ba9a1c",
   "metadata": {},
   "source": [
    "## WEALSEL + MUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f6e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.dictionary_based import MUSE\n",
    "\n",
    "# Fit Model\n",
    "muse_clf = MUSE(anova=True, variance=False, bigrams=True, window_inc=2, alphabet_size=4, use_first_order_differences=True, feature_selection='chi2', p_threshold=0.05, support_probabilities=False, n_jobs=1, random_state=42)\n",
    "muse_clf.fit(X_train_sktime, y_train_sktime)\n",
    "\n",
    "# Predict\n",
    "y_pred_muse = muse_clf.predict(X_test_sktime)\n",
    "\n",
    "accuracy = accuracy_score(y_test_sktime, y_pred_muse)\n",
    "f1 = f1_score(y_test_sktime, y_pred_muse, average='binary')\n",
    "recall = recall_score(y_test_sktime, y_pred_muse, average='binary')\n",
    "precision = precision_score(y_test_sktime, y_pred_muse, average='binary')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2092ee1",
   "metadata": {},
   "source": [
    "## ROCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34818ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "\n",
    "# Fit Model\n",
    "rocket_clf = RocketClassifier(num_kernels=10000, rocket_transform='rocket', max_dilations_per_kernel=32, n_features_per_kernel=4, use_multivariate='yes', n_jobs=1, random_state=42)\n",
    "rocket_clf.fit(X_train_sktime, y_train_sktime)\n",
    "\n",
    "# Predict\n",
    "y_pred_rocket= rocket_clf.predict(X_test_sktime)\n",
    "\n",
    "accuracy = accuracy_score(y_test_sktime, y_pred_rocket)\n",
    "f1 = f1_score(y_test_sktime, y_pred_rocket, average='binary')\n",
    "recall = recall_score(y_test_sktime, y_pred_rocket, average='binary')\n",
    "precision = precision_score(y_test_sktime, y_pred_rocket, average='binary')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750ad4fb",
   "metadata": {},
   "source": [
    "## KNeighborsTimeSeriesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bec9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "\n",
    "# Fit Model\n",
    "KNeighbors_clf = KNeighborsTimeSeriesClassifier(n_neighbors=3, weights='uniform', algorithm='brute_incr', distance='dtw', distance_params=None, distance_mtype=None, pass_train_distances=False, leaf_size=30, n_jobs=None)\n",
    "KNeighbors_clf.fit(X_train_sktime, y_train_sktime)\n",
    "# Predict  \n",
    "y_pred_kneighbors = KNeighbors_clf.predict(X_test_sktime)\n",
    "\n",
    "accuracy = accuracy_score(y_test_sktime, y_pred_kneighbors)\n",
    "f1 = f1_score(y_test_sktime, y_pred_kneighbors, average='weighted')\n",
    "recall = recall_score(y_test_sktime, y_pred_kneighbors, average='weighted')\n",
    "precision = precision_score(y_test_sktime, y_pred_kneighbors, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfd1f5b",
   "metadata": {},
   "source": [
    "## TimeMIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c278d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
